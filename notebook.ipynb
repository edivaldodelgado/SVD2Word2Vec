{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h1> Aplicação do SVD ao dataset em português do Word2Vec </h1>\n",
    "<h3> O objetivo desse trabalho é compreender como o a técnica de Word2Vec funciona e utilizar o modelo de SVD para reduzir as dimensões do dataset de Word2Vec disponibilizado pelo Laboratório de Computação e Linguística da USP.</h3>\n",
    "<h4><ol>\n",
    "    <li>Introdução</li>\n",
    "    <li>Objetivo</li>\n",
    "    <li>Metodologia</li>\n",
    "    <li>Estudo de Caso</li>\n",
    "    <li>Conclusões</li>\n",
    "    <li>Referências</li>\n",
    "</ol></h4>\n",
    "\n",
    "<h4>1. Introdução</h4>\n",
    "\n",
    "<p>Como definir que uma frase ou uma palavra é similar a outra? Para resolver esse problema uma das soluções utilizadas é o treinamento de uma Rede Neural que usa como base uma representação vetorial das palavras. Isso pode ser observado nesse artigo bem explicativo do Luiza Labs [1].</p>\n",
    "\n",
    "<p>Contudo, esse dataset de vetores de palavras (Word2Vec) em geral tem uma alta dimensionalidade, mais de 300 dimensões. Nesse trabalho deseja-se utilizar o método do SVD [2], para reduzir essa dimensionalidade preservando os \"agrupamentos\" encontrados após o treinamento.</p>\n",
    "\n",
    "\n",
    "<h4>2. Objetivo</h4>\n",
    "\n",
    "<p> Com o uso do SVD, reduzir o dataset de 300 para 150, 50 e 2 dimensões. Verificar se ainda são preservadas as principais características, em especial algumas operações conhecidas como:</p>\n",
    "\n",
    "<p><i>Rei - Homem + Mulher = Rainha</i></p>\n",
    "\n",
    "<h4>3. Metodologia</h4>\n",
    "\n",
    "<ul>\n",
    "    <li><p>Usar o código de SVD do Pacote Sci-Kit Learn [3] </p></li>\n",
    "    <li><p>Uso do Modelo Pré-Treinado de Word2Vec [4] </p></li>\n",
    "    <li><p>Aplicação de Visualização [5] </p></li>\n",
    "\n",
    "</ul>\n",
    "\n",
    "<h5>3.1 Representação Vetorial</h5>\n",
    "\n",
    "<h4>Estudo de Caso</h4>\n",
    "\n",
    "<p>Uso do Modelo Pré-Treinado de Word2Vec para português disponibilizado e treinado utilizando o algoritmo Skip-Gram</p>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "import os\n",
    "dirname = os.path.realpath('..')\n",
    "#\n",
    "filename = dirname+'/atividadeiv_SVD2Word2Vec/word2vec-pt-br/exemplo/wiki.pt.trigram.vector'\n",
    "#filename = dirname+'/atividadeiv_SVD2Word2Vec/word2vec-pt-br/exemplo/skip_s300.txt'\n",
    "\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format(filename,binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-94c537cb4a27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# apply SVD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_sims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m#model.init_sims(replace=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/MyDjangoEnv/lib/python3.6/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36minit_sims\u001b[0;34m(self, replace)\u001b[0m\n\u001b[1;32m    809\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msyn0norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msyn0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msyn0norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msyn0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msyn0\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mREAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# apply SVD\n",
    "\n",
    "model.init_sims(replace=False)\n",
    "#model.init_sims(replace=True)\n",
    "\n",
    "\n",
    "result = model.most_similar(positive=['woman', 'king'], negative=['man'])\n",
    "print(\"{}: {:.4f}\".format(*result[0]))\n",
    "\n",
    "#model.wv.syn0  # Input Embedding Matrix\n",
    "#model.syn1     # Output embedding //with hierarchical softmax (hs=1)//\n",
    "#model.syn1neg  # Output embedding //when it uses negative sampling (negative>0)//\n",
    "\n",
    "print(model.wv.syn0)\n",
    "\n",
    "\n",
    "#U, S, Vt = np.linalg.svd(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Referências</h4>\n",
    "\n",
    "[1] https://medium.com/luizalabs/similaridade-entre-t%C3%ADtulos-de-produtos-com-word2vec-5e26199862f0\n",
    "\n",
    "[2] \n",
    "\n",
    "[3] https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.linalg.svd.html\n",
    "\n",
    "[4] https://github.com/felipeparpinelli/word2vec-pt-br"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
