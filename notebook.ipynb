{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h1> Aplicação do SVD ao dataset em português do Word2Vec </h1>\n",
    "<h3> O objetivo desse trabalho é compreender como o a técnica de Word2Vec funciona e utilizar o modelo de SVD para reduzir as dimensões do dataset de Word2Vec disponibilizado pelo Laboratório de Computação e Linguística da USP.</h3>\n",
    "<h4><ol>\n",
    "    <li>Introdução</li>\n",
    "    <li>Objetivo</li>\n",
    "    <li>Metodologia</li>\n",
    "    <li>Estudo de Caso</li>\n",
    "    <li>Conclusões</li>\n",
    "    <li>Referências</li>\n",
    "</ol></h4>\n",
    "\n",
    "<h4>1. Introdução</h4>\n",
    "\n",
    "<p>Como definir que uma frase ou uma palavra é similar a outra? Para resolver esse problema uma das soluções utilizadas é o treinamento de uma Rede Neural que usa como base uma representação vetorial das palavras. Isso pode ser observado nesse artigo bem explicativo do Luiza Labs [1].</p>\n",
    "\n",
    "<p>Contudo, esse dataset de vetores de palavras (Word2Vec) em geral tem uma alta dimensionalidade, mais de 300 dimensões. Nesse trabalho deseja-se utilizar o método do SVD [2], para reduzir essa dimensionalidade preservando os \"agrupamentos\" encontrados após o treinamento.</p>\n",
    "\n",
    "\n",
    "<h4>2. Objetivo</h4>\n",
    "\n",
    "<p> Com o uso do SVD, reduzir o dataset de 300 para 100, 50, 10 e 2 dimensões. Verificar se ainda são preservadas as principais características, em especial algumas operações conhecidas como:</p>\n",
    "\n",
    "<p><i>Rei - Homem + Mulher = Rainha</i></p>\n",
    "\n",
    "<h4>3. Metodologia</h4>\n",
    "\n",
    "<ul>\n",
    "    <li><p>Usar o código de SVD do Numpy [3] </p></li>\n",
    "    <li><p>Uso do Modelo Pré-Treinado de Word2Vec [2] </p></li>\n",
    "    <li><p>Aplicação de Visualização [4] </p></li>\n",
    "\n",
    "</ul>\n",
    "\n",
    "<h5>3.1 Representação Vetorial</h5>\n",
    "\n",
    "<p> Sem dúvidas uma das melhores referências para entendimento da representação vetorial, [2].\n",
    "\n",
    "\n",
    "<h4>4. Estudo de Caso</h4>\n",
    "\n",
    "<p>Uso do Modelo Pré-Treinado de Word2Vec para português disponibilizado e treinado utilizando o algoritmo Skip-Gram, inicialmente foi tentado utilizar o modelo com 300 dimensões, contudo por problemas de memória, não foi possível fazer load de toda a matriz, logo diminuimos o escopo para uma matriz com 300 dimensoes e 20k linhas</p>\n",
    "\n",
    "<p>Verificamos inicialmente quais os indices das palavras a serem testadas para posteriormente fazer esse corte. </p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "import os\n",
    "dirname = os.path.realpath('..')\n",
    "\n",
    "def model_trigram():\n",
    "    filename = dirname+'/SVD2Word2Vec/word2vec_copy/exemplo/wiki.pt.trigram.vector'\n",
    "    model = gensim.models.KeyedVectors.load_word2vec_format(filename,binary=True)\n",
    "    model.init_sims(replace=False)\n",
    "    #model.init_sims(replace=True) # to reduce memory usage\n",
    "    return model\n",
    "    \n",
    "def model_skipgram_usp():\n",
    "    filename = dirname+'/SVD2Word2Vec/word2vec_copy/exemplo/skip_s300.txt'\n",
    "    model = gensim.models.KeyedVectors.load_word2vec_format(filename,binary=False)\n",
    "    model.init_sims(replace=False)\n",
    "    #model.init_sims(replace=True) # to reduce memory usage\n",
    "    return model\n",
    "\n",
    "def model_skipgram_usp_50():\n",
    "    filename = dirname+'/SVD2Word2Vec/word2vec_copy/exemplo/skip_s50.txt'\n",
    "    model = gensim.models.KeyedVectors.load_word2vec_format(filename,binary=False)\n",
    "    model.init_sims(replace=False)\n",
    "    #model.init_sims(replace=True) # to reduce memory usage\n",
    "    return model\n",
    "\n",
    "def compare_Woman_King_Man(model):\n",
    "    result = model.most_similar(positive=['mulher', 'rei'], negative=['homem'])\n",
    "    print(\"\\n{}: {:.4f}\\n\".format(*result[0]))\n",
    "\n",
    "# load model\n",
    "model = model_skipgram_usp()\n",
    "model_50 = model_skipgram_usp_50()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar(vec1,matrix):\n",
    "    \n",
    "    index_list = list()\n",
    "    cossine_distance_list = list()\n",
    "    \n",
    "    cossine_distance = np.dot(vec1,matrix[0])/(np.linalg.norm(vec1)*np.linalg.norm(matrix[0]))\n",
    "    \n",
    "    new_matrix = list()\n",
    "    \n",
    "    for i in range(len(matrix)):\n",
    "        cossine_distance_loop = np.dot(vec1,matrix[i])/(np.linalg.norm(vec1)*np.linalg.norm(matrix[i]))\n",
    "        new_matrix.append(cossine_distance_loop)\n",
    "\n",
    "    index_index = sorted(range(len(new_matrix)), key=lambda k: new_matrix[k])\n",
    "    new_cossine_distance_list = list()\n",
    "    new_index_list = list()\n",
    "        \n",
    "    for i in index_index:\n",
    "        new_cossine_distance_list.append(new_matrix[i])\n",
    "        \n",
    "    index_index = index_index[len(index_index)-10:]\n",
    "    cossine_distance_list = new_cossine_distance_list[len(new_cossine_distance_list)-10:]\n",
    "        \n",
    "    return index_index,cossine_distance_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Shape of Dataset: (929606, 300)\n",
      "\n",
      " Shape of Dataset (reduced): (20000, 300)\n",
      "\n",
      "  -Shape of Matrix U: (20000, 20000)\n",
      "\n",
      "  -Shape of Matrix S: (300,)\n",
      "\n",
      "  -Shape of Matrix Vt: (300, 300)\n"
     ]
    }
   ],
   "source": [
    "#model.wv.syn0  # Input Embedding Matrix\n",
    "#model.syn1     # Output embedding //with hierarchical softmax (hs=1)//\n",
    "#model.syn1neg  # Output embedding //when it uses negative sampling (negative>0)//\n",
    "\n",
    "np_matrix = np.asarray(model.wv.syn0)\n",
    "print('\\n Shape of Dataset: {}'.format(np_matrix.shape))\n",
    "\n",
    "# Reduce number of lines in order to avoid memory problems;\n",
    "np_matrix_reduced = np_matrix[:20000]\n",
    "print('\\n Shape of Dataset (reduced): {}'.format(np_matrix_reduced.shape))\n",
    "\n",
    "U, S, Vt = np.linalg.svd(np_matrix_reduced)\n",
    "\n",
    "print('\\n  -Shape of Matrix U: {}'.format(U.shape))\n",
    "print('\\n  -Shape of Matrix S: {}'.format(S.shape))\n",
    "print('\\n  -Shape of Matrix Vt: {}'.format(Vt.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matrix Reconstruction: \n",
      "\n",
      "\n",
      "Woman Index: 445\n",
      "King Index: 666\n",
      "Man Index: 294\n",
      "Queen Index: 1989\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:12: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  del sys.path[0]\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:14: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMatrix Reconstruction: \\n\")\n",
    "\n",
    "matrix_reconstructed_2_dim = np.matrix(U[:, :2]) * np.diag(S[:2]) * np.matrix(Vt[:2, :])\n",
    "matrix_reconstructed_10_dim = np.matrix(U[:, :10]) * np.diag(S[:10]) * np.matrix(Vt[:10, :])\n",
    "matrix_reconstructed_50_dim = np.matrix(U[:, :50]) * np.diag(S[:50]) * np.matrix(Vt[:50, :])\n",
    "matrix_reconstructed_100_dim = np.matrix(U[:, :100]) * np.diag(S[:100]) * np.matrix(Vt[:100, :])\n",
    "\n",
    "\n",
    "\n",
    "# get the index of the words\n",
    "woman_index = model.wv.vocab['mulher'].index\n",
    "king_index = model.wv.vocab['rei'].index\n",
    "man_index = model.wv.vocab['homem'].index\n",
    "queen_index = model.wv.vocab['rainha'].index\n",
    "\n",
    "print(\"\\nWoman Index: {}\".format(woman_index))\n",
    "print(\"King Index: {}\".format(king_index))\n",
    "print(\"Man Index: {}\".format(man_index))\n",
    "print(\"Queen Index: {}\\n\".format(queen_index))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Obs. podemos verificar que a metodologia está correta com a implementada pelo Gensim Word2Vec<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_matrix(matrix):\n",
    "    new_matrix = list()\n",
    "\n",
    "    for i in matrix:\n",
    "        a = i\n",
    "        a = np.transpose(a)\n",
    "        a = np.squeeze(np.asarray(a))\n",
    "        new_matrix.append(a)\n",
    "\n",
    "    new_matrix = np.asarray(new_matrix)\n",
    "    return new_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " ##### (result from Gensim model) ######\n",
      "\n",
      "rainha: 0.6601\n",
      "\n",
      "\n",
      "\n",
      " ##### (result from new Matrix 300 dim) ######\n",
      "ah-hotep: 0.6332, index: 285429\n",
      "esposa: 0.6358, index: 1278\n",
      "príncipe-herdeiro: 0.6372, index: 53146\n",
      "sobrinha: 0.6386, index: 11072\n",
      "princesa: 0.6451, index: 2872\n",
      "rainha-viúva: 0.6487, index: 115749\n",
      "primogénita: 0.6598, index: 122910\n",
      "consorte: 0.6866, index: 17430\n",
      "rainha: 0.6870, index: 1989\n",
      "rei: 0.7265, index: 666\n",
      "\n",
      "\n",
      "\n",
      "('rei', 0.7265248894691467)\n",
      "('rainha', 0.6869875192642212)\n",
      "('consorte', 0.6865828037261963)\n",
      "('primogénita', 0.6597862243652344)\n",
      "('rainha-viúva', 0.6487346887588501)\n",
      "('princesa', 0.645134449005127)\n",
      "('sobrinha', 0.6385774612426758)\n",
      "('príncipe-herdeiro', 0.6372197270393372)\n",
      "('esposa', 0.6358453631401062)\n",
      "('ah-hotep', 0.6331871747970581)\n",
      "OBSERVA-SE AQUI QUE A METODOLOGIA DE CALCULO ESTÁ CORRETA, O MESMO RESULTADO PARA O MODELO GENSIM TREINADO E O MODELO UTILIZANDO DIRETAMENTE A MATRIX DE PESOS EXTRAÍDA DO MODELO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:20: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " ##### (result from new Matrix 100 dim) ######\n",
      "regente: 0.7210, index: 9014\n",
      "esposa: 0.7271, index: 1278\n",
      "neta: 0.7301, index: 10943\n",
      "rei: 0.7396, index: 666\n",
      "imperatriz: 0.7477, index: 8680\n",
      "filha: 0.7499, index: 784\n",
      "sobrinha: 0.7635, index: 11072\n",
      "princesa: 0.7817, index: 2872\n",
      "rainha: 0.7956, index: 1989\n",
      "consorte: 0.7965, index: 17430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:46: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " ##### (result from new Matrix 50 dim) ######\n",
      "cunhada: 0.7845, index: 17450\n",
      "imperatriz: 0.7904, index: 8680\n",
      "esposa: 0.7906, index: 1278\n",
      "neta: 0.7923, index: 10943\n",
      "filha: 0.7983, index: 784\n",
      "viúva: 0.8001, index: 6150\n",
      "sobrinha: 0.8137, index: 11072\n",
      "princesa: 0.8378, index: 2872\n",
      "rainha: 0.8398, index: 1989\n",
      "consorte: 0.8439, index: 17430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:64: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " ##### (result from new Matrix 10 dim) ######\n",
      "duquesa: 0.9115, index: 10908\n",
      "espírita: 0.9166, index: 15683\n",
      "herdeira: 0.9178, index: 15055\n",
      "regência: 0.9195, index: 12420\n",
      "sofia: 0.9204, index: 6988\n",
      "honra: 0.9242, index: 2442\n",
      "primeira-dama: 0.9262, index: 19593\n",
      "rainha: 0.9326, index: 1989\n",
      "imperatriz: 0.9338, index: 8680\n",
      "princesa: 0.9374, index: 2872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:83: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " ##### (result from new Matrix 2 dim) ######\n",
      "regente: 0.7210, index: 9014\n",
      "esposa: 0.7271, index: 1278\n",
      "neta: 0.7301, index: 10943\n",
      "rei: 0.7396, index: 666\n",
      "imperatriz: 0.7477, index: 8680\n",
      "filha: 0.7499, index: 784\n",
      "sobrinha: 0.7635, index: 11072\n",
      "princesa: 0.7817, index: 2872\n",
      "rainha: 0.7956, index: 1989\n",
      "consorte: 0.7965, index: 17430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:100: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"
     ]
    }
   ],
   "source": [
    "# now compute King - Man + Woman\n",
    "\n",
    "# 1. Find the most similar (result from Gensim model)\n",
    "print(\"\\n\\n ##### (result from Gensim model) ######\")\n",
    "compare_Woman_King_Man(model)\n",
    "\n",
    "# 2. Find the most similar (result direct from the matrix of the trainned model)\n",
    "# obs: We want to find the result result of 1, just to see if the method is correct;\n",
    "woman_vector = np_matrix[woman_index]\n",
    "king_vector = np_matrix[king_index]\n",
    "man_vector = np_matrix[man_index]\n",
    "\n",
    "vec1 = king_vector + woman_vector - man_vector\n",
    "index_index,similarity_list = most_similar(vec1,np_matrix)\n",
    "\n",
    "\n",
    "print(\"\\n\\n ##### (result from new Matrix 300 dim) ######\")\n",
    "k = 0\n",
    "for i in index_index:\n",
    "    print(\"{}: {:.4f}, index: {}\".format(model.wv.index2word[i],similarity_list[k],i))\n",
    "    k += 1\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "result = model.most_similar(np.array([vec1]))\n",
    "for i in result:\n",
    "    print(i)\n",
    "\n",
    "\n",
    "print(\"\\n\\n\\nOBSERVA-SE AQUI QUE A METODOLOGIA DE CALCULO ESTÁ CORRETA, O MESMO RESULTADO PARA O MODELO GENSIM TREINADO E O MODELO UTILIZANDO DIRETAMENTE A MATRIX DE PESOS EXTRAÍDA DO MODELO\\n\\n\\n\")\n",
    "    \n",
    "    \n",
    "# 3. Find the most similar (result from new Matrix 100 dim)\n",
    "matrix_reconstructed_100_dim = modify_matrix(matrix_reconstructed_100_dim)\n",
    "\n",
    "woman_vector = matrix_reconstructed_100_dim[woman_index]\n",
    "king_vector = matrix_reconstructed_100_dim[king_index]\n",
    "man_vector = matrix_reconstructed_100_dim[man_index]\n",
    "\n",
    "vec1 = king_vector - man_vector + woman_vector\n",
    "index_index,similarity_list = most_similar(vec1,matrix_reconstructed_100_dim)\n",
    "\n",
    "\n",
    "print(\"\\n\\n ##### (result from new Matrix 100 dim) ######\")\n",
    "k = 0\n",
    "for i in index_index:\n",
    "    print(\"{}: {:.4f}, index: {}\".format(model.wv.index2word[i],similarity_list[k],i))\n",
    "    k += 1\n",
    "\n",
    "\n",
    "\n",
    "# 4. Find the most similar (result from new Matrix 50 dim)\n",
    "matrix_reconstructed_50_dim = modify_matrix(matrix_reconstructed_50_dim)\n",
    "\n",
    "woman_vector = matrix_reconstructed_50_dim[woman_index]\n",
    "king_vector = matrix_reconstructed_50_dim[king_index]\n",
    "man_vector = matrix_reconstructed_50_dim[man_index]\n",
    "\n",
    "vec1 = king_vector - man_vector + woman_vector\n",
    "index_index,similarity_list = most_similar(vec1,matrix_reconstructed_50_dim)\n",
    "\n",
    "print(\"\\n\\n ##### (result from new Matrix 50 dim) ######\")\n",
    "k = 0\n",
    "for i in index_index:\n",
    "    print(\"{}: {:.4f}, index: {}\".format(model.wv.index2word[i],similarity_list[k],i))\n",
    "    k += 1\n",
    "\n",
    "\n",
    "# 5. Find the most similar (result from new Matrix 10 dim)\n",
    "new_matrix_reconstructed_10_dim = modify_matrix(matrix_reconstructed_10_dim)\n",
    "\n",
    "woman_vector = new_matrix_reconstructed_10_dim[woman_index]\n",
    "king_vector = new_matrix_reconstructed_10_dim[king_index]\n",
    "man_vector = new_matrix_reconstructed_10_dim[man_index]\n",
    "\n",
    "vec1 = king_vector - man_vector + woman_vector\n",
    "index_index,similarity_list = most_similar(vec1,new_matrix_reconstructed_10_dim)\n",
    "\n",
    "\n",
    "print(\"\\n\\n ##### (result from new Matrix 10 dim) ######\")\n",
    "k = 0\n",
    "\n",
    "for i in index_index:\n",
    "    print(\"{}: {:.4f}, index: {}\".format(model.wv.index2word[i],similarity_list[k],i))\n",
    "    k += 1\n",
    "\n",
    "# 6. Find the most similar (result from new Matrix 2 dim)\n",
    "matrix_reconstructed_2_dim = modify_matrix(matrix_reconstructed_2_dim)\n",
    "\n",
    "woman_vector = matrix_reconstructed_2_dim[woman_index]\n",
    "king_vector = matrix_reconstructed_2_dim[king_index]\n",
    "man_vector = matrix_reconstructed_2_dim[man_index]\n",
    "\n",
    "vec1 = king_vector - man_vector + woman_vector\n",
    "index_index,similarity_list = most_similar(vec1,matrix_reconstructed_2_dim)\n",
    "\n",
    "\n",
    "print(\"\\n\\n ##### (result from new Matrix 2 dim) ######\")\n",
    "k = 0\n",
    "for i in index_index:\n",
    "    print(\"{}: {:.4f}, index: {}\".format(model.wv.index2word[i],similarity_list[k],i))\n",
    "    k += 1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p> Agora vamos comparar o resultado para 50 dimensoes usando o SVD e para um modelo pre-treinado em 50 dimensões </p>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Shape of Dataset: (929606, 50)\n",
      "\n",
      " Shape of Dataset (reduced): (20000, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "#model.wv.syn0  # Input Embedding Matrix\n",
    "#model.syn1     # Output embedding //with hierarchical softmax (hs=1)//\n",
    "#model.syn1neg  # Output embedding //when it uses negative sampling (negative>0)//\n",
    "\n",
    "np_matrix = np.asarray(model_50.wv.syn0)\n",
    "print('\\n Shape of Dataset: {}'.format(np_matrix.shape))\n",
    "\n",
    "# Reduce number of lines in order to avoid memory problems;\n",
    "np_matrix_reduced = np_matrix[:20000]\n",
    "print('\\n Shape of Dataset (reduced): {}'.format(np_matrix_reduced.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " ##### (result from new Matrix 50 dim) ######\n",
      "consorte: 0.8546, index: 17430\n",
      "imperatriz-mãe: 0.8548, index: 158221\n",
      "imperatriz: 0.8556, index: 8680\n",
      "infanta: 0.8662, index: 22059\n",
      "esposa: 0.8672, index: 1278\n",
      "rainha-consorte: 0.8763, index: 119481\n",
      "rainha-viúva: 0.8763, index: 115594\n",
      "rainha-mãe: 0.8869, index: 57958\n",
      "rainha: 0.8892, index: 1989\n",
      "princesa: 0.8987, index: 2872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:12: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " ##### (result from new Matrix 50 dim SVD) ######\n",
      "vínculos: 0.7845, index: 17450\n",
      "imperatriz: 0.7904, index: 8680\n",
      "esposa: 0.7906, index: 1278\n",
      "neta: 0.7923, index: 10943\n",
      "filha: 0.7983, index: 784\n",
      "viúva: 0.8001, index: 6150\n",
      "sobrinha: 0.8137, index: 11072\n",
      "princesa: 0.8378, index: 2872\n",
      "rainha: 0.8398, index: 1989\n",
      "consorte: 0.8439, index: 17430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:26: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"
     ]
    }
   ],
   "source": [
    "# 1. Find the most similar (result direct from the matrix of the trainned model 50 dim)\n",
    "woman_vector = np_matrix[woman_index]\n",
    "king_vector = np_matrix[king_index]\n",
    "man_vector = np_matrix[man_index]\n",
    "\n",
    "vec1 = king_vector - man_vector + woman_vector\n",
    "index_index,similarity_list = most_similar(vec1,np_matrix)\n",
    "\n",
    "print(\"\\n\\n ##### (result from new Matrix 50 dim) ######\")\n",
    "k = 0\n",
    "for i in index_index:\n",
    "    print(\"{}: {:.4f}, index: {}\".format(model_50.wv.index2word[i],similarity_list[k],i))\n",
    "    k += 1\n",
    "    \n",
    "# 2. Find the most similar (result from Matrix 50 dim AFTER SVD on the 300 dim matrix)\n",
    "woman_vector = matrix_reconstructed_50_dim[woman_index]\n",
    "king_vector = matrix_reconstructed_50_dim[king_index]\n",
    "man_vector = matrix_reconstructed_50_dim[man_index]\n",
    "\n",
    "vec1 = king_vector - man_vector + woman_vector\n",
    "index_index,similarity_list = most_similar(vec1,matrix_reconstructed_50_dim)\n",
    "\n",
    "print(\"\\n\\n ##### (result from new Matrix 50 dim SVD) ######\")\n",
    "k = 0\n",
    "for i in index_index:\n",
    "    print(\"{}: {:.4f}, index: {}\".format(model_50.wv.index2word[i],similarity_list[k],i))\n",
    "    k += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>5. Conclusões</h4>\n",
    "\n",
    "<p> A ideia inicial era realizar o comparativo de diversas operações do Word2Vec, contudo, muito do tempo foi gasto debugando o código para que funcionasse com a quantidade de memória disponível. Tentei inclusive usar uma máquina virtual da IBM Cloud para carregar totalmente mas sem sucesso.</p>\n",
    "\n",
    "<p> Além disso, grande parte do trabalho de leitura para entendimento do problema, como de fato funciona o modelo Word2Vec para assim então aplicar o método do SVD </p>\n",
    "\n",
    "<p> Por fim podemos ver que a redução de dimensionalidade preserva algumas das características originais, no caso de 10 dimensões temos ainda resultados interessantes, contudo, para 2 dimensões, os resultados são bem ruins. Outro fato interessante é que a similaridade, medida pelo cosseno entre os vetores, fica cada vez mais alta, ainda que a similaridade real não seja perfeita. É interessante notar que isso acontece por que quando diminuindo dimensões estamos \"achatando\" os vetores, assim, de fato, eles cada vez mais vão estar mais próximos, de maneira geral. </p>\n",
    "\n",
    "<p> Foi comparado ao final um modelo treinado especificamente para 50 dimensoes, ou seja no treinamento da Rede Neural que originou essa matriz, tinham 50 neuronios na camada intermediária. E foi comparado o resultado com uma matriz reduzida pelo SVD, de 300 para 50 dimensões. Os resultados ficaram bem próximos, ainda que a vantagem esteja com a rede treinada diretamente para 50 dimensões.</p>\n",
    "\n",
    "<p> Uma comparação a ser feita que pode ser interessante é realizar o treinamento novamente do modelo Word2Vec só que dessa vez já para a dimensão reduzida, ou seja, treinar para 2, 10 features. E comparar os resultados da Rede Neural treinada já na dimensão inferior com os resultados do SVD aplicado em uma matriz com dimensão superior, como no caso desse trabalho. </p>\n",
    "\n",
    "\n",
    "<p> Nesse repositório ainda encontra-se uma aplicação para visualização dessas palavras próximas e das operações com vetores, contudo, não foi possível inputar no modelo Gensim (que é a base para essas operações na aplicação Word2Vec-pt-br) as novas matrizes calculadas após o SVD. Seria necessário mais tempo de pesquisa para descobrir como fazer essa alteração. Ainda assim, como teve-se que reduzir o número de linhas utilizadas na matriz, teríamos problema de compatibilidade. <p>\n",
    "    \n",
    "<p> Mas a ideia era ter uma representação visual do que está acontecendo com os vetores ao fazer a redução de dimensão. </p>\n",
    "\n",
    "<h4>6. Referências</h4>\n",
    "\n",
    "[1] https://medium.com/luizalabs/similaridade-entre-t%C3%ADtulos-de-produtos-com-word2vec-5e26199862f0\n",
    "\n",
    "[2] http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/\n",
    "\n",
    "[3] https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.linalg.svd.html\n",
    "\n",
    "[4] https://github.com/felipeparpinelli/word2vec-pt-br"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
